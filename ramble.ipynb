{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from pathlib import Path\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    REPO_ROOT: Path = Path(\"./\")\n",
    "    data_dir: Path = REPO_ROOT / \"data\"\n",
    "    output_dir: Path = REPO_ROOT / \"outputs\"\n",
    "\n",
    "\n",
    "config = Config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bike Rentals (Regression)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_bike_data(data_dir=\"./\"):\n",
    "    \"\"\"Loads and preprocesses the bike sharing dataset.\"\"\"\n",
    "\n",
    "    bike = pd.read_csv(f\"{data_dir}/bike+sharing+dataset/day.csv\")\n",
    "    bike[\"weekday\"] = pd.Categorical(\n",
    "        bike[\"weekday\"], categories=range(7), ordered=True\n",
    "    ).rename_categories([\"SUN\", \"MON\", \"TUE\", \"WED\", \"THU\", \"FRI\", \"SAT\"])\n",
    "    bike[\"holiday\"] = pd.Categorical(\n",
    "        bike[\"holiday\"], categories=[0, 1], ordered=True\n",
    "    ).rename_categories([\"NO HOLIDAY\", \"HOLIDAY\"])\n",
    "    bike[\"workingday\"] = pd.Categorical(\n",
    "        bike[\"workingday\"], categories=[0, 1], ordered=True\n",
    "    ).rename_categories([\"NO WORKING DAY\", \"WORKING DAY\"])\n",
    "    bike[\"season\"] = pd.Categorical(\n",
    "        bike[\"season\"], categories=range(1, 5), ordered=True\n",
    "    ).rename_categories([\"WINTER\", \"SPRING\", \"SUMMER\", \"FALL\"])\n",
    "    bike[\"weathersit\"] = pd.Categorical(\n",
    "        bike[\"weathersit\"], categories=range(1, 4), ordered=True\n",
    "    ).rename_categories([\"GOOD\", \"MISTY\", \"RAIN/SNOW/STORM\"])\n",
    "    bike[\"mnth\"] = pd.Categorical(\n",
    "        bike[\"mnth\"], categories=range(1, 13), ordered=True\n",
    "    ).rename_categories(\n",
    "        [\n",
    "            \"JAN\",\n",
    "            \"FEB\",\n",
    "            \"MAR\",\n",
    "            \"APR\",\n",
    "            \"MAY\",\n",
    "            \"JUN\",\n",
    "            \"JUL\",\n",
    "            \"AUG\",\n",
    "            \"SEP\",\n",
    "            \"OCT\",\n",
    "            \"NOV\",\n",
    "            \"DEC\",\n",
    "        ]\n",
    "    )\n",
    "\n",
    "    bike[\"yr\"] = np.where(bike[\"yr\"] == 0, 2011, 2012)\n",
    "    bike[\"yr\"] = pd.Categorical(bike[\"yr\"])\n",
    "    bike[\"dteday\"] = pd.to_datetime(bike[\"dteday\"])\n",
    "    bike[\"days_since_2011\"] = (bike[\"dteday\"] - bike[\"dteday\"].min()).dt.days\n",
    "    bike[\"temp\"] = bike[\"temp\"] * (39 - (-8)) + (-8)\n",
    "    bike[\"atemp\"] = bike[\"atemp\"] * (50 - (16)) + (16)\n",
    "    bike[\"windspeed\"] = 67 * bike[\"windspeed\"]\n",
    "    bike[\"hum\"] = 100 * bike[\"hum\"]\n",
    "\n",
    "    return bike.drop(columns=[\"instant\", \"dteday\", \"registered\", \"casual\", \"atemp\"])\n",
    "\n",
    "\n",
    "# TODO\n",
    "# これ不要？\n",
    "bike_features_of_interest = [\n",
    "    \"season\",\n",
    "    \"holiday\",\n",
    "    \"workingday\",\n",
    "    \"weathersit\",\n",
    "    \"temp\",\n",
    "    \"hum\",\n",
    "    \"windspeed\",\n",
    "    \"days_since_2011\",\n",
    "]\n",
    "df_bike = preprocess_bike_data(data_dir=config.data_dir)\n",
    "df_bike_X = df_bike.drop(\"cnt\", axis=1)\n",
    "df_bike_y = df_bike[\"cnt\"]\n",
    "df_bike_X_train, df_bike_X_test, df_bike_y_train, df_bike_y_test = train_test_split(\n",
    "    df_bike_X, df_bike_y, test_size=0.2, random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['season', 'yr', 'mnth', 'holiday', 'weekday', 'workingday',\n",
       "       'weathersit', 'temp', 'hum', 'windspeed', 'cnt', 'days_since_2011'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bike.columns\n",
    "# memo\n",
    "# \"mnth\",\"weekday\"が余分の列として入っている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### YouTube Spam Comments (Text Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_ycomments(html_string):\n",
    "    if pd.isna(html_string):\n",
    "        return html_string\n",
    "    return re.sub(\"<.*?>\", \"\", html_string)\n",
    "\n",
    "\n",
    "# TODO\n",
    "# 5MVをまとめて1つのファイルにした方がいいのか確認\n",
    "df_ycomments = pd.read_csv(\n",
    "    f\"{config.data_dir}/youtube+spam+collection/Youtube01-Psy.csv\"\n",
    ")\n",
    "df_ycomments[\"CONTENT\"] = df_ycomments[\"CONTENT\"].apply(clean_ycomments)\n",
    "# Convert to ASCII\n",
    "df_ycomments[\"CONTENT\"] = (\n",
    "    df_ycomments[\"CONTENT\"]\n",
    "    .astype(str)\n",
    "    .str.encode(\"ascii\", \"ignore\")\n",
    "    .str.decode(\"ascii\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>COMMENT_ID</th>\n",
       "      <th>AUTHOR</th>\n",
       "      <th>DATE</th>\n",
       "      <th>CONTENT</th>\n",
       "      <th>CLASS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU</td>\n",
       "      <td>Julius NM</td>\n",
       "      <td>2013-11-07T06:20:48</td>\n",
       "      <td>Huh, anyway check out this you[tube] channel: ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A</td>\n",
       "      <td>adam riyati</td>\n",
       "      <td>2013-11-07T12:37:15</td>\n",
       "      <td>Hey guys check out my new channel and our firs...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8</td>\n",
       "      <td>Evgeny Murashkin</td>\n",
       "      <td>2013-11-08T17:34:21</td>\n",
       "      <td>just for test I have to say murdev.com</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>z13jhp0bxqncu512g22wvzkasxmvvzjaz04</td>\n",
       "      <td>ElNino Melendez</td>\n",
       "      <td>2013-11-09T08:28:43</td>\n",
       "      <td>me shaking my sexy ass on my channel enjoy ^_^</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>z13fwbwp1oujthgqj04chlngpvzmtt3r3dw</td>\n",
       "      <td>GsMega</td>\n",
       "      <td>2013-11-10T16:05:38</td>\n",
       "      <td>watch?v=vtaRGgvGtWQ   Check this out .</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    COMMENT_ID            AUTHOR  \\\n",
       "0  LZQPQhLyRh80UYxNuaDWhIGQYNQ96IuCg-AYWqNPjpU         Julius NM   \n",
       "1  LZQPQhLyRh_C2cTtd9MvFRJedxydaVW-2sNg5Diuo4A       adam riyati   \n",
       "2  LZQPQhLyRh9MSZYnf8djyk0gEF9BHDPYrrK-qCczIY8  Evgeny Murashkin   \n",
       "3          z13jhp0bxqncu512g22wvzkasxmvvzjaz04   ElNino Melendez   \n",
       "4          z13fwbwp1oujthgqj04chlngpvzmtt3r3dw            GsMega   \n",
       "\n",
       "                  DATE                                            CONTENT  \\\n",
       "0  2013-11-07T06:20:48  Huh, anyway check out this you[tube] channel: ...   \n",
       "1  2013-11-07T12:37:15  Hey guys check out my new channel and our firs...   \n",
       "2  2013-11-08T17:34:21             just for test I have to say murdev.com   \n",
       "3  2013-11-09T08:28:43    me shaking my sexy ass on my channel enjoy ^_^    \n",
       "4  2013-11-10T16:05:38             watch?v=vtaRGgvGtWQ   Check this out .   \n",
       "\n",
       "   CLASS  \n",
       "0      1  \n",
       "1      1  \n",
       "2      1  \n",
       "3      1  \n",
       "4      1  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_ycomments.head()\n",
    "# memo\n",
    "# \"COMMENT_ID\",\"AUTHOR\",\"DATE\"が余分の列として入っている"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Risk Factors for Cervical Cancer (Classification)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rfcc = pd.read_csv(f\"{config.data_dir}/risk_factors_cervical_cancer.csv\")\n",
    "df_rfcc = df_rfcc.drop(columns=[\"Citology\", \"Schiller\", \"Hinselmann\"])\n",
    "df_rfcc[\"Biopsy\"] = pd.Categorical(\n",
    "    df_rfcc[\"Biopsy\"], categories=[0, 1], ordered=True\n",
    ").rename_categories([\"Healthy\", \"Cancer\"])\n",
    "df_rfcc = df_rfcc[\n",
    "    [\n",
    "        \"Age\",\n",
    "        \"Number of sexual partners\",\n",
    "        \"First sexual intercourse\",\n",
    "        \"Num of pregnancies\",\n",
    "        \"Smokes\",\n",
    "        \"Smokes (years)\",\n",
    "        \"Hormonal Contraceptives\",\n",
    "        \"Hormonal Contraceptives (years)\",\n",
    "        \"IUD\",\n",
    "        \"IUD (years)\",\n",
    "        \"STDs\",\n",
    "        \"STDs (number)\",\n",
    "        \"STDs: Number of diagnosis\",\n",
    "        \"STDs: Time since first diagnosis\",\n",
    "        \"STDs: Time since last diagnosis\",\n",
    "        \"Biopsy\",\n",
    "    ]\n",
    "]\n",
    "# Impute missing values using the most frequent value (mode)\n",
    "imputer = SimpleImputer(strategy=\"most_frequent\")\n",
    "df_rfcc_imputed = imputer.fit_transform(\n",
    "    df_rfcc.drop(\"Biopsy\", axis=1)\n",
    ")  # Fit SimpleImputer on numerical data only\n",
    "df_rfcc_imputed = pd.DataFrame(\n",
    "    df_rfcc_imputed, columns=df_rfcc.columns[:-1]\n",
    ")  # Drop target column from output\n",
    "df_rfcc = pd.concat(\n",
    "    [df_rfcc_imputed, df_rfcc[\"Biopsy\"]], axis=1\n",
    ")  # Concatenate back numerical and target features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
